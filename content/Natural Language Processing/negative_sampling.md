Title: Optimize Computational Efficiency of Skip-Gram with Negative Sampling
Tags: data-mining, nlp, word2vec, co-occurrence matrix, vector space model, word vectors, window size, skip-gram, neural network, negative sampling, stochastic gradient descent, learning rate
Date: 2019-05-24 09:00
Slug: optimizing_computational_efficiency_of_skip-gram_with_negative_sampling
Subtitle:
Keywords: 
Featured_Image: images/featured_images/negative_sampling.png
readingTime: 20
Social_Media_Description: How is neural network used in language modeling to capture relationships among words?
IndexPreview: Negative sampling
Summary: {% notebook downloads/notebooks/Optimizing_Computational_Efficiency_of_Skip-Gram_with_Negative_Sampling.ipynb cells[1:2] %}

{% notebook downloads/notebooks/Optimizing_Computational_Efficiency_of_Skip-Gram_with_Negative_Sampling.ipynb cells[:] %}